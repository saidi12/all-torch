{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from utils import OxfordDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_v = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "transform_t = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),        # Flip 50% of images\n",
    "    transforms.RandomRotation(degrees=15),         # Rotate Â±15 degrees\n",
    "    transforms.ColorJitter(                        # Color augmentation\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OxfordDataset(\"flower_data\", transform=transform_v)\n",
    "validation_dataset = OxfordDataset(\"flower_data\", transform=transform_v)\n",
    "test_dataset = OxfordDataset(\"flower_data\", transform=transform_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.70 * len(train_dataset))\n",
    "validation_split = int(0.15 * len(train_dataset))\n",
    "test_split = len(train_dataset) - train_split - validation_split\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(train_dataset),generator=torch.Generator().manual_seed(42)).tolist()\n",
    "\n",
    "train_indices = indices[:train_split]\n",
    "validation_indices = indices[train_split:train_split+validation_split]\n",
    "test_indices = indices[train_split+validation_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(train_dataset,train_indices)\n",
    "val_dataset = Subset(validation_dataset,validation_indices)\n",
    "test_dataset = Subset(test_dataset,test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.7069, -1.7240, -1.7240,  ..., -1.8268, -1.7925, -1.7925],\n",
       "          [-1.7240, -1.7412, -1.7583,  ..., -1.8097, -1.8268, -1.8439],\n",
       "          [-1.7412, -1.7583, -1.7925,  ..., -1.8097, -1.8610, -1.8953],\n",
       "          ...,\n",
       "          [-1.6727, -1.6555, -1.6555,  ...,  1.6667,  2.0605,  2.1462],\n",
       "          [-1.7240, -1.6727, -1.6213,  ...,  1.0159,  1.6667,  2.0605],\n",
       "          [-1.7240, -1.6727, -1.6213,  ...,  0.7077,  1.0673,  1.6153]],\n",
       " \n",
       "         [[-1.4755, -1.4930, -1.5455,  ..., -1.1954, -1.2129, -1.2304],\n",
       "          [-1.4580, -1.4755, -1.5105,  ..., -1.2129, -1.2479, -1.2829],\n",
       "          [-1.4580, -1.4755, -1.5105,  ..., -1.2479, -1.3354, -1.3880],\n",
       "          ...,\n",
       "          [-1.2479, -1.1779, -1.1253,  ...,  1.0805,  1.4832,  1.5707],\n",
       "          [-1.2479, -1.1954, -1.1429,  ...,  0.4328,  1.0630,  1.4657],\n",
       "          [-1.2479, -1.1954, -1.1429,  ...,  0.1001,  0.4503,  0.9930]],\n",
       " \n",
       "         [[-1.6476, -1.6650, -1.6824,  ..., -1.7696, -1.7347, -1.6999],\n",
       "          [-1.6476, -1.6650, -1.6999,  ..., -1.7347, -1.7347, -1.7347],\n",
       "          [-1.6476, -1.6650, -1.6999,  ..., -1.7347, -1.7522, -1.7696],\n",
       "          ...,\n",
       "          [-1.6302, -1.5953, -1.5779,  ...,  2.0823,  2.4831,  2.5703],\n",
       "          [-1.6824, -1.6302, -1.5779,  ...,  1.4025,  2.0648,  2.4831],\n",
       "          [-1.6824, -1.6302, -1.5779,  ...,  1.0365,  1.4200,  2.0125]]]),\n",
       " np.uint8(0))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8189"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_split,batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_split, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 53,  59,  50,  50,  59,  92,  87,  87,  81,  81,  65,  74,  87,   2,\n",
      "         86,  88,  49,  71,  50,  55,  87,  63,  72,  73,  50,  58,  85,  18,\n",
      "         45, 100,  64,  38], dtype=torch.uint8)\n",
      "53\n",
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_loader:\n",
    "    print(label)\n",
    "    print(label[0].item())\n",
    "    print(image.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32,kernel_size=3,padding=1,stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64,kernel_size=3,stride=2,padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=512,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512*3*3,512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(512,102)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)  \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0005, weight_decay=0.0005)\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, loss_function):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:  # Changed condition\n",
    "            avg_loss = running_loss / 10  # Now correct\n",
    "            acc = 100. * correct / total\n",
    "            print(f' [{(batch_idx + 1) * len(data)}/{len(train_loader.dataset)}]'\n",
    "                  f' Loss: {avg_loss:.3f} | Accuracy: {acc:.1f} %')\n",
    "            running_loss = 0.0  # Only reset loss, keep accuracy cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,validation_loader,device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, targets) in enumerate(validation_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            output = model(data)\n",
    "            _,predicted = output.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return 100. * correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      " [320/5732] Loss: 0.853 | Accuracy: 74.7 %\n",
      " [640/5732] Loss: 0.888 | Accuracy: 74.1 %\n",
      " [960/5732] Loss: 0.923 | Accuracy: 73.1 %\n",
      " [1280/5732] Loss: 0.889 | Accuracy: 73.4 %\n",
      " [1600/5732] Loss: 0.885 | Accuracy: 73.1 %\n",
      " [1920/5732] Loss: 0.957 | Accuracy: 72.7 %\n",
      " [2240/5732] Loss: 0.824 | Accuracy: 73.4 %\n",
      " [2560/5732] Loss: 0.819 | Accuracy: 73.5 %\n",
      " [2880/5732] Loss: 0.861 | Accuracy: 73.6 %\n",
      " [3200/5732] Loss: 0.873 | Accuracy: 73.6 %\n",
      " [3520/5732] Loss: 0.897 | Accuracy: 73.7 %\n",
      " [3840/5732] Loss: 0.952 | Accuracy: 73.6 %\n",
      " [4160/5732] Loss: 0.921 | Accuracy: 73.3 %\n",
      " [4480/5732] Loss: 0.853 | Accuracy: 73.4 %\n",
      " [4800/5732] Loss: 0.821 | Accuracy: 73.6 %\n",
      " [5120/5732] Loss: 0.823 | Accuracy: 73.6 %\n",
      " [5440/5732] Loss: 0.931 | Accuracy: 73.4 %\n",
      " [720/5732] Loss: 0.839 | Accuracy: 73.5 %\n",
      "Validation Accuracy : 62.05211726384365\n",
      "Epoch : 1\n",
      " [320/5732] Loss: 0.839 | Accuracy: 74.1 %\n",
      " [640/5732] Loss: 0.753 | Accuracy: 75.8 %\n",
      " [960/5732] Loss: 0.728 | Accuracy: 75.9 %\n",
      " [1280/5732] Loss: 0.761 | Accuracy: 75.9 %\n",
      " [1600/5732] Loss: 0.878 | Accuracy: 75.6 %\n",
      " [1920/5732] Loss: 0.873 | Accuracy: 75.5 %\n",
      " [2240/5732] Loss: 0.748 | Accuracy: 75.5 %\n",
      " [2560/5732] Loss: 0.794 | Accuracy: 75.8 %\n",
      " [2880/5732] Loss: 0.726 | Accuracy: 75.9 %\n",
      " [3200/5732] Loss: 0.776 | Accuracy: 75.6 %\n",
      " [3520/5732] Loss: 0.911 | Accuracy: 75.4 %\n",
      " [3840/5732] Loss: 0.807 | Accuracy: 75.4 %\n",
      " [4160/5732] Loss: 0.820 | Accuracy: 75.5 %\n",
      " [4480/5732] Loss: 0.765 | Accuracy: 75.7 %\n",
      " [4800/5732] Loss: 0.746 | Accuracy: 75.9 %\n",
      " [5120/5732] Loss: 0.772 | Accuracy: 76.0 %\n",
      " [5440/5732] Loss: 0.926 | Accuracy: 75.9 %\n",
      " [720/5732] Loss: 0.802 | Accuracy: 75.7 %\n",
      "Validation Accuracy : 61.726384364820845\n",
      "Epoch : 2\n",
      " [320/5732] Loss: 0.840 | Accuracy: 77.2 %\n",
      " [640/5732] Loss: 0.811 | Accuracy: 75.3 %\n",
      " [960/5732] Loss: 0.725 | Accuracy: 75.9 %\n",
      " [1280/5732] Loss: 0.696 | Accuracy: 76.6 %\n",
      " [1600/5732] Loss: 0.739 | Accuracy: 76.8 %\n",
      " [1920/5732] Loss: 0.746 | Accuracy: 77.2 %\n",
      " [2240/5732] Loss: 0.715 | Accuracy: 77.5 %\n",
      " [2560/5732] Loss: 0.739 | Accuracy: 77.3 %\n",
      " [2880/5732] Loss: 0.631 | Accuracy: 77.5 %\n",
      " [3200/5732] Loss: 0.812 | Accuracy: 77.2 %\n",
      " [3520/5732] Loss: 0.708 | Accuracy: 77.2 %\n",
      " [3840/5732] Loss: 0.685 | Accuracy: 77.4 %\n",
      " [4160/5732] Loss: 0.667 | Accuracy: 77.5 %\n",
      " [4480/5732] Loss: 0.763 | Accuracy: 77.4 %\n",
      " [4800/5732] Loss: 0.714 | Accuracy: 77.5 %\n",
      " [5120/5732] Loss: 0.787 | Accuracy: 77.4 %\n",
      " [5440/5732] Loss: 0.830 | Accuracy: 77.3 %\n",
      " [720/5732] Loss: 0.777 | Accuracy: 77.2 %\n",
      "Validation Accuracy : 61.237785016286644\n",
      "Epoch : 3\n",
      " [320/5732] Loss: 0.762 | Accuracy: 77.8 %\n",
      " [640/5732] Loss: 0.738 | Accuracy: 77.0 %\n",
      " [960/5732] Loss: 0.853 | Accuracy: 75.7 %\n",
      " [1280/5732] Loss: 0.686 | Accuracy: 76.3 %\n",
      " [1600/5732] Loss: 0.691 | Accuracy: 76.4 %\n",
      " [1920/5732] Loss: 0.717 | Accuracy: 76.8 %\n",
      " [2240/5732] Loss: 0.712 | Accuracy: 76.8 %\n",
      " [2560/5732] Loss: 0.648 | Accuracy: 77.2 %\n",
      " [2880/5732] Loss: 0.615 | Accuracy: 77.6 %\n",
      " [3200/5732] Loss: 0.719 | Accuracy: 77.6 %\n",
      " [3520/5732] Loss: 0.570 | Accuracy: 78.1 %\n",
      " [3840/5732] Loss: 0.644 | Accuracy: 78.3 %\n",
      " [4160/5732] Loss: 0.694 | Accuracy: 78.2 %\n",
      " [4480/5732] Loss: 0.676 | Accuracy: 78.1 %\n",
      " [4800/5732] Loss: 0.639 | Accuracy: 78.2 %\n",
      " [5120/5732] Loss: 0.748 | Accuracy: 77.9 %\n",
      " [5440/5732] Loss: 0.646 | Accuracy: 77.9 %\n",
      " [720/5732] Loss: 0.750 | Accuracy: 77.8 %\n",
      "Validation Accuracy : 62.13355048859935\n",
      "Epoch : 4\n",
      " [320/5732] Loss: 0.550 | Accuracy: 83.8 %\n",
      " [640/5732] Loss: 0.596 | Accuracy: 84.1 %\n",
      " [960/5732] Loss: 0.579 | Accuracy: 82.5 %\n",
      " [1280/5732] Loss: 0.640 | Accuracy: 81.8 %\n",
      " [1600/5732] Loss: 0.551 | Accuracy: 81.8 %\n",
      " [1920/5732] Loss: 0.653 | Accuracy: 81.4 %\n",
      " [2240/5732] Loss: 0.583 | Accuracy: 81.3 %\n",
      " [2560/5732] Loss: 0.534 | Accuracy: 81.6 %\n",
      " [2880/5732] Loss: 0.615 | Accuracy: 81.6 %\n",
      " [3200/5732] Loss: 0.691 | Accuracy: 81.3 %\n",
      " [3520/5732] Loss: 0.665 | Accuracy: 81.2 %\n",
      " [3840/5732] Loss: 0.694 | Accuracy: 80.9 %\n",
      " [4160/5732] Loss: 0.729 | Accuracy: 80.7 %\n",
      " [4480/5732] Loss: 0.617 | Accuracy: 80.6 %\n",
      " [4800/5732] Loss: 0.586 | Accuracy: 80.7 %\n",
      " [5120/5732] Loss: 0.581 | Accuracy: 80.8 %\n",
      " [5440/5732] Loss: 0.573 | Accuracy: 80.9 %\n",
      " [720/5732] Loss: 0.557 | Accuracy: 81.0 %\n",
      "Validation Accuracy : 62.13355048859935\n",
      "Epoch : 5\n",
      " [320/5732] Loss: 0.540 | Accuracy: 83.8 %\n",
      " [640/5732] Loss: 0.632 | Accuracy: 83.1 %\n",
      " [960/5732] Loss: 0.545 | Accuracy: 82.8 %\n",
      " [1280/5732] Loss: 0.563 | Accuracy: 82.4 %\n",
      " [1600/5732] Loss: 0.581 | Accuracy: 82.2 %\n",
      " [1920/5732] Loss: 0.586 | Accuracy: 81.7 %\n",
      " [2240/5732] Loss: 0.553 | Accuracy: 81.9 %\n",
      " [2560/5732] Loss: 0.502 | Accuracy: 82.3 %\n",
      " [2880/5732] Loss: 0.603 | Accuracy: 82.2 %\n",
      " [3200/5732] Loss: 0.665 | Accuracy: 82.0 %\n",
      " [3520/5732] Loss: 0.636 | Accuracy: 81.8 %\n",
      " [3840/5732] Loss: 0.521 | Accuracy: 81.9 %\n",
      " [4160/5732] Loss: 0.564 | Accuracy: 82.1 %\n",
      " [4480/5732] Loss: 0.576 | Accuracy: 81.9 %\n",
      " [4800/5732] Loss: 0.469 | Accuracy: 82.3 %\n",
      " [5120/5732] Loss: 0.555 | Accuracy: 82.4 %\n",
      " [5440/5732] Loss: 0.610 | Accuracy: 82.2 %\n",
      " [720/5732] Loss: 0.523 | Accuracy: 82.4 %\n",
      "Validation Accuracy : 61.88925081433225\n",
      "Epoch : 6\n",
      " [320/5732] Loss: 0.551 | Accuracy: 83.4 %\n",
      " [640/5732] Loss: 0.541 | Accuracy: 83.1 %\n",
      " [960/5732] Loss: 0.536 | Accuracy: 83.1 %\n",
      " [1280/5732] Loss: 0.522 | Accuracy: 82.9 %\n",
      " [1600/5732] Loss: 0.417 | Accuracy: 83.6 %\n",
      " [1920/5732] Loss: 0.452 | Accuracy: 84.4 %\n",
      " [2240/5732] Loss: 0.476 | Accuracy: 84.2 %\n",
      " [2560/5732] Loss: 0.476 | Accuracy: 84.1 %\n",
      " [2880/5732] Loss: 0.352 | Accuracy: 84.6 %\n",
      " [3200/5732] Loss: 0.505 | Accuracy: 84.7 %\n",
      " [3520/5732] Loss: 0.638 | Accuracy: 84.1 %\n",
      " [3840/5732] Loss: 0.530 | Accuracy: 84.0 %\n",
      " [4160/5732] Loss: 0.505 | Accuracy: 84.3 %\n",
      " [4480/5732] Loss: 0.531 | Accuracy: 84.1 %\n",
      " [4800/5732] Loss: 0.454 | Accuracy: 84.1 %\n",
      " [5120/5732] Loss: 0.550 | Accuracy: 84.1 %\n",
      " [5440/5732] Loss: 0.428 | Accuracy: 84.2 %\n",
      " [720/5732] Loss: 0.518 | Accuracy: 84.1 %\n",
      "Validation Accuracy : 62.29641693811075\n",
      "Epoch : 7\n",
      " [320/5732] Loss: 0.464 | Accuracy: 82.8 %\n",
      " [640/5732] Loss: 0.447 | Accuracy: 84.4 %\n",
      " [960/5732] Loss: 0.504 | Accuracy: 83.9 %\n",
      " [1280/5732] Loss: 0.462 | Accuracy: 84.5 %\n",
      " [1600/5732] Loss: 0.503 | Accuracy: 84.6 %\n",
      " [1920/5732] Loss: 0.407 | Accuracy: 85.2 %\n",
      " [2240/5732] Loss: 0.458 | Accuracy: 85.0 %\n",
      " [2560/5732] Loss: 0.474 | Accuracy: 84.9 %\n",
      " [2880/5732] Loss: 0.488 | Accuracy: 84.9 %\n",
      " [3200/5732] Loss: 0.560 | Accuracy: 84.7 %\n",
      " [3520/5732] Loss: 0.593 | Accuracy: 84.4 %\n",
      " [3840/5732] Loss: 0.446 | Accuracy: 84.7 %\n",
      " [4160/5732] Loss: 0.520 | Accuracy: 84.6 %\n",
      " [4480/5732] Loss: 0.471 | Accuracy: 84.7 %\n",
      " [4800/5732] Loss: 0.520 | Accuracy: 84.7 %\n",
      " [5120/5732] Loss: 0.637 | Accuracy: 84.5 %\n",
      " [5440/5732] Loss: 0.421 | Accuracy: 84.7 %\n",
      " [720/5732] Loss: 0.556 | Accuracy: 84.6 %\n",
      "Validation Accuracy : 60.34201954397394\n",
      "Epoch : 8\n",
      " [320/5732] Loss: 0.624 | Accuracy: 82.5 %\n",
      " [640/5732] Loss: 0.465 | Accuracy: 83.8 %\n",
      " [960/5732] Loss: 0.383 | Accuracy: 84.9 %\n",
      " [1280/5732] Loss: 0.367 | Accuracy: 85.7 %\n",
      " [1600/5732] Loss: 0.475 | Accuracy: 85.7 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     validation_acc = validation(model, validation_loader, device)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidation Accuracy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, optimizer, loss_function)\u001b[39m\n\u001b[32m      5\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     data, labels = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels.to(device)\n\u001b[32m      9\u001b[39m     optimizer.zero_grad()\n\u001b[32m     10\u001b[39m     output = model(data)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for idx in range(num_epochs):\n",
    "    print(f\"Epoch : {idx}\")\n",
    "    train_epoch(model,train_loader,optimizer,loss_function)\n",
    "    validation_acc = validation(model, validation_loader, device)\n",
    "    print(f\"Validation Accuracy : {validation_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
