{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "\n",
    "from utils import OxfordDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OxfordDataset(\"flower_data\", transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4568, -0.4739, -0.4739,  ...,  0.1426,  0.1426,  0.0912],\n",
       "          [-0.4397, -0.4739, -0.4739,  ...,  0.2282,  0.2453,  0.2624],\n",
       "          [-0.3883, -0.4226, -0.4568,  ...,  0.3652,  0.3481,  0.3309],\n",
       "          ...,\n",
       "          [-1.2959, -1.2959, -1.3130,  ..., -1.3815, -1.4158, -1.4500],\n",
       "          [-1.3815, -1.3815, -1.3644,  ..., -1.3302, -1.2959, -1.3130],\n",
       "          [-1.4500, -1.4500, -1.4500,  ..., -1.1075, -1.0733, -1.1247]],\n",
       " \n",
       "         [[ 0.4853,  0.5203,  0.5728,  ...,  0.5203,  0.5028,  0.4328],\n",
       "          [ 0.5378,  0.5553,  0.5903,  ...,  0.6954,  0.6604,  0.6078],\n",
       "          [ 0.5903,  0.5728,  0.5903,  ...,  0.8529,  0.8179,  0.7654],\n",
       "          ...,\n",
       "          [-1.0028, -1.0028, -1.0028,  ..., -1.1954, -1.2129, -1.2479],\n",
       "          [-1.0903, -1.0903, -1.1253,  ..., -1.0553, -1.0553, -1.1429],\n",
       "          [-1.1779, -1.1779, -1.1954,  ..., -0.8277, -0.8452, -0.9678]],\n",
       " \n",
       "         [[-1.4733, -1.5256, -1.5953,  ..., -0.3578, -0.3578, -0.4101],\n",
       "          [-1.4559, -1.5430, -1.5779,  ..., -0.2010, -0.1661, -0.1312],\n",
       "          [-1.4036, -1.4733, -1.5430,  ..., -0.0615, -0.0615, -0.0441],\n",
       "          ...,\n",
       "          [-1.0724, -1.0724, -1.0724,  ..., -1.5779, -1.5430, -1.5430],\n",
       "          [-1.1247, -1.1421, -1.1596,  ..., -1.2990, -1.1944, -1.2467],\n",
       "          [-1.2293, -1.2467, -1.2467,  ..., -1.1073, -0.9853, -1.0550]]]),\n",
       " np.uint8(76))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.70 * len(dataset))\n",
    "validation_split = int(0.15 * len(dataset))\n",
    "test_split = len(dataset) - train_split - validation_split\n",
    "\n",
    "train_dataset, validation_split, test_split = random_split(dataset, [train_split, validation_split, test_split])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_split,batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_split, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 53,  59,  50,  50,  59,  92,  87,  87,  81,  81,  65,  74,  87,   2,\n",
      "         86,  88,  49,  71,  50,  55,  87,  63,  72,  73,  50,  58,  85,  18,\n",
      "         45, 100,  64,  38], dtype=torch.uint8)\n",
      "53\n",
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_loader:\n",
    "    print(label)\n",
    "    print(label[0].item())\n",
    "    print(image.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32,kernel_size=3,padding=1,stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64,kernel_size=3,stride=2,padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=512,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512*3*3,512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(512,102)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)  \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0005, weight_decay=0.0005)\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, loss_function):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:  # Changed condition\n",
    "            avg_loss = running_loss / 10  # Now correct\n",
    "            acc = 100. * correct / total\n",
    "            print(f' [{(batch_idx + 1) * len(data)}/{len(train_loader.dataset)}]'\n",
    "                  f' Loss: {avg_loss:.3f} | Accuracy: {acc:.1f} %')\n",
    "            running_loss = 0.0  # Only reset loss, keep accuracy cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,validation_loader,device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, targets) in enumerate(validation_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            output = model(data)\n",
    "            _,predicted = output.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return 100. * correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      " [320/5732] Loss: 4.631 | Accuracy: 0.3 %\n",
      " [640/5732] Loss: 4.586 | Accuracy: 1.7 %\n",
      " [960/5732] Loss: 4.591 | Accuracy: 2.1 %\n",
      " [1280/5732] Loss: 4.589 | Accuracy: 2.1 %\n",
      " [1600/5732] Loss: 4.521 | Accuracy: 2.6 %\n",
      " [1920/5732] Loss: 4.521 | Accuracy: 2.7 %\n",
      " [2240/5732] Loss: 4.477 | Accuracy: 2.7 %\n",
      " [2560/5732] Loss: 4.399 | Accuracy: 2.6 %\n",
      " [2880/5732] Loss: 4.333 | Accuracy: 2.7 %\n",
      " [3200/5732] Loss: 4.325 | Accuracy: 2.8 %\n",
      " [3520/5732] Loss: 4.355 | Accuracy: 3.0 %\n",
      " [3840/5732] Loss: 4.267 | Accuracy: 3.3 %\n",
      " [4160/5732] Loss: 4.186 | Accuracy: 3.6 %\n",
      " [4480/5732] Loss: 4.191 | Accuracy: 3.7 %\n",
      " [4800/5732] Loss: 4.168 | Accuracy: 3.9 %\n",
      " [5120/5732] Loss: 4.207 | Accuracy: 4.0 %\n",
      " [5440/5732] Loss: 4.151 | Accuracy: 4.0 %\n",
      " [720/5732] Loss: 4.075 | Accuracy: 4.1 %\n",
      "Validation Accuracy : 7.49185667752443\n",
      "Epoch : 1\n",
      " [320/5732] Loss: 4.057 | Accuracy: 7.5 %\n",
      " [640/5732] Loss: 4.046 | Accuracy: 7.7 %\n",
      " [960/5732] Loss: 3.956 | Accuracy: 7.5 %\n",
      " [1280/5732] Loss: 3.970 | Accuracy: 7.5 %\n",
      " [1600/5732] Loss: 3.940 | Accuracy: 7.2 %\n",
      " [1920/5732] Loss: 3.941 | Accuracy: 7.0 %\n",
      " [2240/5732] Loss: 3.955 | Accuracy: 7.1 %\n",
      " [2560/5732] Loss: 3.999 | Accuracy: 7.0 %\n",
      " [2880/5732] Loss: 3.916 | Accuracy: 7.3 %\n",
      " [3200/5732] Loss: 3.865 | Accuracy: 7.3 %\n",
      " [3520/5732] Loss: 3.833 | Accuracy: 7.3 %\n",
      " [3840/5732] Loss: 3.937 | Accuracy: 7.5 %\n",
      " [4160/5732] Loss: 3.803 | Accuracy: 7.7 %\n",
      " [4480/5732] Loss: 3.784 | Accuracy: 7.8 %\n",
      " [4800/5732] Loss: 3.720 | Accuracy: 8.0 %\n",
      " [5120/5732] Loss: 3.697 | Accuracy: 8.2 %\n",
      " [5440/5732] Loss: 3.749 | Accuracy: 8.4 %\n",
      " [720/5732] Loss: 3.839 | Accuracy: 8.4 %\n",
      "Validation Accuracy : 14.006514657980455\n",
      "Epoch : 2\n",
      " [320/5732] Loss: 3.671 | Accuracy: 11.2 %\n",
      " [640/5732] Loss: 3.774 | Accuracy: 9.5 %\n",
      " [960/5732] Loss: 3.625 | Accuracy: 10.1 %\n",
      " [1280/5732] Loss: 3.698 | Accuracy: 10.2 %\n",
      " [1600/5732] Loss: 3.536 | Accuracy: 11.0 %\n",
      " [1920/5732] Loss: 3.588 | Accuracy: 10.7 %\n",
      " [2240/5732] Loss: 3.583 | Accuracy: 10.8 %\n",
      " [2560/5732] Loss: 3.627 | Accuracy: 10.7 %\n",
      " [2880/5732] Loss: 3.595 | Accuracy: 10.8 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for idx in range(num_epochs):\n",
    "    print(f\"Epoch : {idx}\")\n",
    "    train_epoch(model,train_loader,optimizer,loss_function)\n",
    "    validation_acc = validation(model, validation_loader, device)\n",
    "    print(f\"Validation Accuracy : {validation_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
