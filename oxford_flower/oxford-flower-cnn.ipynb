{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from utils import OxfordDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_v = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "transform_t = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),        # Flip 50% of images\n",
    "    transforms.RandomRotation(degrees=15),         # Rotate Â±15 degrees\n",
    "    transforms.ColorJitter(                        # Color augmentation\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OxfordDataset(\"flower_data\", transform=transform_v)\n",
    "validation_dataset = OxfordDataset(\"flower_data\", transform=transform_v)\n",
    "test_dataset = OxfordDataset(\"flower_data\", transform=transform_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.70 * len(train_dataset))\n",
    "validation_split = int(0.15 * len(train_dataset))\n",
    "test_split = len(train_dataset) - train_split - validation_split\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(train_dataset),generator=torch.Generator().manual_seed(42)).tolist()\n",
    "\n",
    "train_indices = indices[:train_split]\n",
    "validation_indices = indices[train_split:train_split+validation_split]\n",
    "test_indices = indices[train_split+validation_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(train_dataset,train_indices)\n",
    "val_dataset = Subset(validation_dataset,validation_indices)\n",
    "test_dataset = Subset(test_dataset,test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8189"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(val_dataset,batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([63, 76, 32, 87, 94, 15, 93, 72, 76, 34, 87, 80, 43, 42, 22, 53, 31,  4,\n",
      "        77,  1, 40, 41, 72, 49, 76, 12, 90, 55,  7, 14, 36,  6],\n",
      "       dtype=torch.uint8)\n",
      "63\n",
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_loader:\n",
    "    print(label)\n",
    "    print(label[0].item())\n",
    "    print(image.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32,kernel_size=3,padding=1,stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2) # 224 -> 112\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64,kernel_size=3,stride=2,padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 112 -> 56 -> 28\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128,kernel_size=3,stride=2,padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 28 -> 14 -> 7\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=512,kernel_size=3,stride=2,padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # 7 -> 4 -> 2\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512,1024)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(1024,102)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)  \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0005, weight_decay=0.0005)\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, loss_function):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:  # Changed condition\n",
    "            avg_loss = running_loss / 10  # Now correct\n",
    "            acc = 100. * correct / total\n",
    "            print(f' [{(batch_idx + 1) * len(data)}/{len(train_loader.dataset)}]'\n",
    "                  f' Loss: {avg_loss:.3f} | Accuracy: {acc:.1f} %')\n",
    "            running_loss = 0.0  # Only reset loss, keep accuracy cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,validation_loader,device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, targets) in enumerate(validation_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            output = model(data)\n",
    "            _,predicted = output.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return 100. * correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      " [320/5732] Loss: 1.799 | Accuracy: 46.9 %\n",
      " [640/5732] Loss: 1.909 | Accuracy: 48.0 %\n",
      " [960/5732] Loss: 1.787 | Accuracy: 48.3 %\n",
      " [1280/5732] Loss: 1.662 | Accuracy: 49.7 %\n",
      " [1600/5732] Loss: 1.641 | Accuracy: 50.2 %\n",
      " [1920/5732] Loss: 1.841 | Accuracy: 49.3 %\n",
      " [2240/5732] Loss: 1.761 | Accuracy: 49.5 %\n",
      " [2560/5732] Loss: 1.781 | Accuracy: 49.2 %\n",
      " [2880/5732] Loss: 1.789 | Accuracy: 48.9 %\n",
      " [3200/5732] Loss: 1.664 | Accuracy: 49.0 %\n",
      " [3520/5732] Loss: 1.841 | Accuracy: 48.9 %\n",
      " [3840/5732] Loss: 1.736 | Accuracy: 49.1 %\n",
      " [4160/5732] Loss: 1.805 | Accuracy: 49.0 %\n",
      " [4480/5732] Loss: 1.726 | Accuracy: 49.1 %\n",
      " [4800/5732] Loss: 1.912 | Accuracy: 49.1 %\n",
      " [5120/5732] Loss: 1.817 | Accuracy: 49.2 %\n",
      " [5440/5732] Loss: 1.862 | Accuracy: 49.0 %\n",
      " [720/5732] Loss: 1.924 | Accuracy: 49.0 %\n",
      "Validation Accuracy : 46.416938110749186\n",
      "Epoch : 1\n",
      " [320/5732] Loss: 1.644 | Accuracy: 54.4 %\n",
      " [640/5732] Loss: 1.656 | Accuracy: 53.1 %\n",
      " [960/5732] Loss: 1.613 | Accuracy: 54.3 %\n",
      " [1280/5732] Loss: 1.512 | Accuracy: 54.7 %\n",
      " [1600/5732] Loss: 1.505 | Accuracy: 55.1 %\n",
      " [1920/5732] Loss: 1.583 | Accuracy: 55.6 %\n",
      " [2240/5732] Loss: 1.576 | Accuracy: 55.5 %\n",
      " [2560/5732] Loss: 1.505 | Accuracy: 55.5 %\n",
      " [2880/5732] Loss: 1.640 | Accuracy: 55.3 %\n",
      " [3200/5732] Loss: 1.753 | Accuracy: 54.8 %\n",
      " [3520/5732] Loss: 1.688 | Accuracy: 54.5 %\n",
      " [3840/5732] Loss: 1.758 | Accuracy: 54.2 %\n",
      " [4160/5732] Loss: 1.596 | Accuracy: 54.2 %\n",
      " [4480/5732] Loss: 1.667 | Accuracy: 54.2 %\n",
      " [4800/5732] Loss: 1.595 | Accuracy: 54.3 %\n",
      " [5120/5732] Loss: 1.508 | Accuracy: 54.6 %\n",
      " [5440/5732] Loss: 1.619 | Accuracy: 54.6 %\n",
      " [720/5732] Loss: 1.598 | Accuracy: 54.3 %\n",
      "Validation Accuracy : 48.534201954397396\n",
      "Epoch : 2\n",
      " [320/5732] Loss: 1.503 | Accuracy: 58.1 %\n",
      " [640/5732] Loss: 1.421 | Accuracy: 57.7 %\n",
      " [960/5732] Loss: 1.473 | Accuracy: 56.9 %\n",
      " [1280/5732] Loss: 1.492 | Accuracy: 55.9 %\n",
      " [1600/5732] Loss: 1.386 | Accuracy: 56.6 %\n",
      " [1920/5732] Loss: 1.519 | Accuracy: 55.9 %\n",
      " [2240/5732] Loss: 1.466 | Accuracy: 55.8 %\n",
      " [2560/5732] Loss: 1.583 | Accuracy: 55.4 %\n",
      " [2880/5732] Loss: 1.389 | Accuracy: 55.9 %\n",
      " [3200/5732] Loss: 1.263 | Accuracy: 56.4 %\n",
      " [3520/5732] Loss: 1.524 | Accuracy: 56.1 %\n",
      " [3840/5732] Loss: 1.341 | Accuracy: 56.4 %\n",
      " [4160/5732] Loss: 1.392 | Accuracy: 56.5 %\n",
      " [4480/5732] Loss: 1.552 | Accuracy: 56.4 %\n",
      " [4800/5732] Loss: 1.554 | Accuracy: 56.3 %\n",
      " [5120/5732] Loss: 1.447 | Accuracy: 56.4 %\n",
      " [5440/5732] Loss: 1.402 | Accuracy: 56.6 %\n",
      " [720/5732] Loss: 1.242 | Accuracy: 56.9 %\n",
      "Validation Accuracy : 48.28990228013029\n",
      "Epoch : 3\n",
      " [320/5732] Loss: 1.279 | Accuracy: 63.8 %\n",
      " [640/5732] Loss: 1.286 | Accuracy: 62.0 %\n",
      " [960/5732] Loss: 1.206 | Accuracy: 63.6 %\n",
      " [1280/5732] Loss: 1.306 | Accuracy: 62.7 %\n",
      " [1600/5732] Loss: 1.329 | Accuracy: 62.5 %\n",
      " [1920/5732] Loss: 1.287 | Accuracy: 62.2 %\n",
      " [2240/5732] Loss: 1.240 | Accuracy: 62.0 %\n",
      " [2560/5732] Loss: 1.253 | Accuracy: 62.1 %\n",
      " [2880/5732] Loss: 1.375 | Accuracy: 61.9 %\n",
      " [3200/5732] Loss: 1.180 | Accuracy: 62.3 %\n",
      " [3520/5732] Loss: 1.310 | Accuracy: 62.2 %\n",
      " [3840/5732] Loss: 1.292 | Accuracy: 62.2 %\n",
      " [4160/5732] Loss: 1.270 | Accuracy: 62.2 %\n",
      " [4480/5732] Loss: 1.532 | Accuracy: 61.5 %\n",
      " [4800/5732] Loss: 1.397 | Accuracy: 61.5 %\n",
      " [5120/5732] Loss: 1.414 | Accuracy: 61.4 %\n",
      " [5440/5732] Loss: 1.167 | Accuracy: 61.5 %\n",
      " [720/5732] Loss: 1.260 | Accuracy: 61.2 %\n",
      "Validation Accuracy : 47.557003257328994\n",
      "Epoch : 4\n",
      " [320/5732] Loss: 1.150 | Accuracy: 67.2 %\n",
      " [640/5732] Loss: 1.073 | Accuracy: 67.3 %\n",
      " [960/5732] Loss: 1.205 | Accuracy: 65.7 %\n",
      " [1280/5732] Loss: 1.090 | Accuracy: 66.4 %\n",
      " [1600/5732] Loss: 1.216 | Accuracy: 66.2 %\n",
      " [1920/5732] Loss: 1.065 | Accuracy: 66.3 %\n",
      " [2240/5732] Loss: 1.003 | Accuracy: 66.6 %\n",
      " [2560/5732] Loss: 1.010 | Accuracy: 66.6 %\n",
      " [2880/5732] Loss: 1.150 | Accuracy: 66.7 %\n",
      " [3200/5732] Loss: 1.209 | Accuracy: 66.4 %\n",
      " [3520/5732] Loss: 1.054 | Accuracy: 66.7 %\n",
      " [3840/5732] Loss: 1.313 | Accuracy: 66.2 %\n",
      " [4160/5732] Loss: 1.227 | Accuracy: 66.1 %\n",
      " [4480/5732] Loss: 1.214 | Accuracy: 65.9 %\n",
      " [4800/5732] Loss: 1.074 | Accuracy: 66.0 %\n",
      " [5120/5732] Loss: 1.084 | Accuracy: 66.2 %\n",
      " [5440/5732] Loss: 1.126 | Accuracy: 66.3 %\n",
      " [720/5732] Loss: 1.277 | Accuracy: 65.9 %\n",
      "Validation Accuracy : 51.465798045602604\n",
      "Epoch : 5\n",
      " [320/5732] Loss: 1.091 | Accuracy: 71.2 %\n",
      " [640/5732] Loss: 1.156 | Accuracy: 68.6 %\n",
      " [960/5732] Loss: 1.073 | Accuracy: 68.8 %\n",
      " [1280/5732] Loss: 0.952 | Accuracy: 69.3 %\n",
      " [1600/5732] Loss: 1.029 | Accuracy: 69.2 %\n",
      " [1920/5732] Loss: 1.136 | Accuracy: 68.3 %\n",
      " [2240/5732] Loss: 0.991 | Accuracy: 68.5 %\n",
      " [2560/5732] Loss: 1.087 | Accuracy: 68.4 %\n",
      " [2880/5732] Loss: 0.998 | Accuracy: 68.5 %\n",
      " [3200/5732] Loss: 0.906 | Accuracy: 68.9 %\n",
      " [3520/5732] Loss: 0.914 | Accuracy: 69.2 %\n",
      " [3840/5732] Loss: 1.069 | Accuracy: 69.0 %\n",
      " [4160/5732] Loss: 1.114 | Accuracy: 68.9 %\n",
      " [4480/5732] Loss: 1.081 | Accuracy: 68.8 %\n",
      " [4800/5732] Loss: 1.156 | Accuracy: 68.5 %\n",
      " [5120/5732] Loss: 0.949 | Accuracy: 68.8 %\n",
      " [5440/5732] Loss: 1.047 | Accuracy: 68.8 %\n",
      " [720/5732] Loss: 1.107 | Accuracy: 68.7 %\n",
      "Validation Accuracy : 50.244299674267104\n",
      "Epoch : 6\n",
      " [320/5732] Loss: 0.959 | Accuracy: 71.9 %\n",
      " [640/5732] Loss: 1.003 | Accuracy: 70.8 %\n",
      " [960/5732] Loss: 0.906 | Accuracy: 70.9 %\n",
      " [1280/5732] Loss: 0.834 | Accuracy: 71.7 %\n",
      " [1600/5732] Loss: 0.913 | Accuracy: 71.6 %\n",
      " [1920/5732] Loss: 0.907 | Accuracy: 71.7 %\n",
      " [2240/5732] Loss: 0.870 | Accuracy: 71.7 %\n",
      " [2560/5732] Loss: 0.865 | Accuracy: 72.1 %\n",
      " [2880/5732] Loss: 0.808 | Accuracy: 72.5 %\n",
      " [3200/5732] Loss: 0.906 | Accuracy: 72.1 %\n",
      " [3520/5732] Loss: 1.008 | Accuracy: 72.1 %\n",
      " [3840/5732] Loss: 0.940 | Accuracy: 72.0 %\n",
      " [4160/5732] Loss: 0.958 | Accuracy: 71.9 %\n",
      " [4480/5732] Loss: 0.818 | Accuracy: 72.1 %\n",
      " [4800/5732] Loss: 0.984 | Accuracy: 71.9 %\n",
      " [5120/5732] Loss: 0.855 | Accuracy: 72.1 %\n",
      " [5440/5732] Loss: 0.900 | Accuracy: 72.1 %\n",
      " [720/5732] Loss: 0.887 | Accuracy: 72.2 %\n",
      "Validation Accuracy : 51.0586319218241\n",
      "Epoch : 7\n",
      " [320/5732] Loss: 0.794 | Accuracy: 76.9 %\n",
      " [640/5732] Loss: 0.801 | Accuracy: 76.2 %\n",
      " [960/5732] Loss: 0.802 | Accuracy: 76.5 %\n",
      " [1280/5732] Loss: 0.771 | Accuracy: 75.6 %\n",
      " [1600/5732] Loss: 0.714 | Accuracy: 76.3 %\n",
      " [1920/5732] Loss: 0.871 | Accuracy: 76.1 %\n",
      " [2240/5732] Loss: 0.806 | Accuracy: 76.1 %\n",
      " [2560/5732] Loss: 0.752 | Accuracy: 76.2 %\n",
      " [2880/5732] Loss: 0.698 | Accuracy: 76.3 %\n",
      " [3200/5732] Loss: 0.789 | Accuracy: 76.3 %\n",
      " [3520/5732] Loss: 0.815 | Accuracy: 76.0 %\n",
      " [3840/5732] Loss: 0.873 | Accuracy: 75.6 %\n",
      " [4160/5732] Loss: 0.861 | Accuracy: 75.3 %\n",
      " [4480/5732] Loss: 0.778 | Accuracy: 75.4 %\n",
      " [4800/5732] Loss: 0.851 | Accuracy: 75.1 %\n",
      " [5120/5732] Loss: 0.741 | Accuracy: 75.1 %\n",
      " [5440/5732] Loss: 0.819 | Accuracy: 75.2 %\n",
      " [720/5732] Loss: 1.011 | Accuracy: 75.0 %\n",
      "Validation Accuracy : 51.872964169381106\n",
      "Epoch : 8\n",
      " [320/5732] Loss: 0.673 | Accuracy: 79.4 %\n",
      " [640/5732] Loss: 0.666 | Accuracy: 79.2 %\n",
      " [960/5732] Loss: 0.667 | Accuracy: 80.0 %\n",
      " [1280/5732] Loss: 0.645 | Accuracy: 79.5 %\n",
      " [1600/5732] Loss: 0.702 | Accuracy: 79.4 %\n",
      " [1920/5732] Loss: 0.655 | Accuracy: 79.5 %\n",
      " [2240/5732] Loss: 0.733 | Accuracy: 79.2 %\n",
      " [2560/5732] Loss: 0.713 | Accuracy: 79.0 %\n",
      " [2880/5732] Loss: 0.732 | Accuracy: 78.9 %\n",
      " [3200/5732] Loss: 0.703 | Accuracy: 79.0 %\n",
      " [3520/5732] Loss: 0.674 | Accuracy: 79.1 %\n",
      " [3840/5732] Loss: 0.648 | Accuracy: 79.0 %\n",
      " [4160/5732] Loss: 0.704 | Accuracy: 78.8 %\n",
      " [4480/5732] Loss: 0.834 | Accuracy: 78.7 %\n",
      " [4800/5732] Loss: 0.755 | Accuracy: 78.7 %\n",
      " [5120/5732] Loss: 0.673 | Accuracy: 78.7 %\n",
      " [5440/5732] Loss: 0.811 | Accuracy: 78.5 %\n",
      " [720/5732] Loss: 0.707 | Accuracy: 78.4 %\n",
      "Validation Accuracy : 52.28013029315961\n",
      "Epoch : 9\n",
      " [320/5732] Loss: 0.632 | Accuracy: 80.6 %\n",
      " [640/5732] Loss: 0.550 | Accuracy: 80.9 %\n",
      " [960/5732] Loss: 0.568 | Accuracy: 81.7 %\n",
      " [1280/5732] Loss: 0.588 | Accuracy: 81.4 %\n",
      " [1600/5732] Loss: 0.718 | Accuracy: 80.0 %\n",
      " [1920/5732] Loss: 0.692 | Accuracy: 79.9 %\n",
      " [2240/5732] Loss: 0.594 | Accuracy: 80.3 %\n",
      " [2560/5732] Loss: 0.531 | Accuracy: 80.6 %\n",
      " [2880/5732] Loss: 0.547 | Accuracy: 80.8 %\n",
      " [3200/5732] Loss: 0.572 | Accuracy: 80.8 %\n",
      " [3520/5732] Loss: 0.522 | Accuracy: 80.9 %\n",
      " [3840/5732] Loss: 0.611 | Accuracy: 80.9 %\n",
      " [4160/5732] Loss: 0.644 | Accuracy: 80.9 %\n",
      " [4480/5732] Loss: 0.721 | Accuracy: 80.7 %\n",
      " [4800/5732] Loss: 0.726 | Accuracy: 80.8 %\n",
      " [5120/5732] Loss: 0.734 | Accuracy: 80.5 %\n",
      " [5440/5732] Loss: 0.602 | Accuracy: 80.6 %\n",
      " [720/5732] Loss: 0.665 | Accuracy: 80.5 %\n",
      "Validation Accuracy : 50.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for idx in range(num_epochs):\n",
    "    print(f\"Epoch : {idx}\")\n",
    "    train_epoch(model,train_loader,optimizer,loss_function)\n",
    "    validation_acc = validation(model, validation_loader, device)\n",
    "    print(f\"Validation Accuracy : {validation_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.77542717656631\n"
     ]
    }
   ],
   "source": [
    "test_acc = validation(model,test_loader,device)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
